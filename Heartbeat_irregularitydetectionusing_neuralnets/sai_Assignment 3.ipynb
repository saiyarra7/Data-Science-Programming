{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sai_Assignment 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this assignment, we will focus on healthcare. This data set is made available by MIT. It contains data about 9,026 heartbeat measurements. Each row represents a single measurement (captured on a timeline). There are a total of 80 data points (columns). This is a multiclass classification task: predict whether the measurement represents a normal heartbeat or other anomalies. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description of Variables\n",
    "\n",
    "You will use the **hearbeat_cleaned.csv** data set for this assignment. Each row represents a single measurement. Columns labeled as T1 from T80 are the time steps on the timeline (there are 80 time steps, each time step has only one measurement). \n",
    "\n",
    "The last column is the target variable. It shows the label (category) of the measurement as follows:<br>\n",
    "0 = Normal<br>\n",
    "1 = Supraventricular premature beat<br>\n",
    "2 = Premature ventricular contraction<br>\n",
    "3 = Fusion of ventricular and normal beat<br>\n",
    "4 = Unclassifiable beat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goal\n",
    "\n",
    "Use the data set **hearbeat_cleaned.csv** to predict the column called **Target**. The input variables are columns labeled as **T1 to T80**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission:\n",
    "\n",
    "Please save and submit this Jupyter notebook file. The correctness of the code matters for your grade. **Readability and organization of your code is also important.** You may lose points for submitting unreadable/undecipherable code. Therefore, use markdown cells to create sections, and use comments where necessary.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Note:\n",
    "\n",
    "The data is cleaned up. There are no uneueal length sequences. And, there is no zero padding. So, you shouldn't use any `Masking` layer (like I mentioned in the lecture). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read and Prepare the Data (1 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>T1</th>\n",
       "      <th>T2</th>\n",
       "      <th>T3</th>\n",
       "      <th>T4</th>\n",
       "      <th>T5</th>\n",
       "      <th>T6</th>\n",
       "      <th>T7</th>\n",
       "      <th>T8</th>\n",
       "      <th>T9</th>\n",
       "      <th>T10</th>\n",
       "      <th>...</th>\n",
       "      <th>T72</th>\n",
       "      <th>T73</th>\n",
       "      <th>T74</th>\n",
       "      <th>T75</th>\n",
       "      <th>T76</th>\n",
       "      <th>T77</th>\n",
       "      <th>T78</th>\n",
       "      <th>T79</th>\n",
       "      <th>T80</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.987</td>\n",
       "      <td>0.892</td>\n",
       "      <td>0.461</td>\n",
       "      <td>0.1130</td>\n",
       "      <td>0.1490</td>\n",
       "      <td>0.1900</td>\n",
       "      <td>0.1650</td>\n",
       "      <td>0.1620</td>\n",
       "      <td>0.1470</td>\n",
       "      <td>0.1380</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1970</td>\n",
       "      <td>0.1970</td>\n",
       "      <td>0.1960</td>\n",
       "      <td>0.2030</td>\n",
       "      <td>0.201</td>\n",
       "      <td>0.1990</td>\n",
       "      <td>0.2010</td>\n",
       "      <td>0.205</td>\n",
       "      <td>0.2080</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.918</td>\n",
       "      <td>0.621</td>\n",
       "      <td>0.1330</td>\n",
       "      <td>0.1050</td>\n",
       "      <td>0.1250</td>\n",
       "      <td>0.1170</td>\n",
       "      <td>0.0898</td>\n",
       "      <td>0.0703</td>\n",
       "      <td>0.0781</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1950</td>\n",
       "      <td>0.1910</td>\n",
       "      <td>0.1520</td>\n",
       "      <td>0.1720</td>\n",
       "      <td>0.207</td>\n",
       "      <td>0.2110</td>\n",
       "      <td>0.2070</td>\n",
       "      <td>0.207</td>\n",
       "      <td>0.1720</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.751</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.1040</td>\n",
       "      <td>0.0961</td>\n",
       "      <td>0.0519</td>\n",
       "      <td>0.0442</td>\n",
       "      <td>0.0416</td>\n",
       "      <td>0.0364</td>\n",
       "      <td>0.0857</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2260</td>\n",
       "      <td>0.2420</td>\n",
       "      <td>0.2440</td>\n",
       "      <td>0.2860</td>\n",
       "      <td>0.468</td>\n",
       "      <td>0.8160</td>\n",
       "      <td>0.9770</td>\n",
       "      <td>0.452</td>\n",
       "      <td>0.0519</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.740</td>\n",
       "      <td>0.235</td>\n",
       "      <td>0.0464</td>\n",
       "      <td>0.0722</td>\n",
       "      <td>0.0567</td>\n",
       "      <td>0.0103</td>\n",
       "      <td>0.0155</td>\n",
       "      <td>0.0284</td>\n",
       "      <td>0.0155</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0851</td>\n",
       "      <td>0.0747</td>\n",
       "      <td>0.0515</td>\n",
       "      <td>0.0593</td>\n",
       "      <td>0.067</td>\n",
       "      <td>0.0361</td>\n",
       "      <td>0.1210</td>\n",
       "      <td>0.451</td>\n",
       "      <td>0.8690</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.833</td>\n",
       "      <td>0.309</td>\n",
       "      <td>0.0191</td>\n",
       "      <td>0.1010</td>\n",
       "      <td>0.1200</td>\n",
       "      <td>0.1040</td>\n",
       "      <td>0.0874</td>\n",
       "      <td>0.0765</td>\n",
       "      <td>0.0765</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4210</td>\n",
       "      <td>0.8030</td>\n",
       "      <td>0.9510</td>\n",
       "      <td>0.467</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0519</td>\n",
       "      <td>0.082</td>\n",
       "      <td>0.0628</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      T1     T2     T3      T4      T5      T6      T7      T8      T9  \\\n",
       "0  0.987  0.892  0.461  0.1130  0.1490  0.1900  0.1650  0.1620  0.1470   \n",
       "1  1.000  0.918  0.621  0.1330  0.1050  0.1250  0.1170  0.0898  0.0703   \n",
       "2  1.000  0.751  0.143  0.1040  0.0961  0.0519  0.0442  0.0416  0.0364   \n",
       "3  1.000  0.740  0.235  0.0464  0.0722  0.0567  0.0103  0.0155  0.0284   \n",
       "4  1.000  0.833  0.309  0.0191  0.1010  0.1200  0.1040  0.0874  0.0765   \n",
       "\n",
       "      T10  ...     T72     T73     T74     T75    T76     T77     T78    T79  \\\n",
       "0  0.1380  ...  0.1970  0.1970  0.1960  0.2030  0.201  0.1990  0.2010  0.205   \n",
       "1  0.0781  ...  0.1950  0.1910  0.1520  0.1720  0.207  0.2110  0.2070  0.207   \n",
       "2  0.0857  ...  0.2260  0.2420  0.2440  0.2860  0.468  0.8160  0.9770  0.452   \n",
       "3  0.0155  ...  0.0851  0.0747  0.0515  0.0593  0.067  0.0361  0.1210  0.451   \n",
       "4  0.0765  ...  0.2050  0.4210  0.8030  0.9510  0.467  0.0000  0.0519  0.082   \n",
       "\n",
       "      T80  Target  \n",
       "0  0.2080       0  \n",
       "1  0.1720       0  \n",
       "2  0.0519       0  \n",
       "3  0.8690       0  \n",
       "4  0.0628       0  \n",
       "\n",
       "[5 rows x 81 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heartbeat = pd.read_csv(\"heartbeat_cleaned.csv\")\n",
    "heartbeat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5572, 81)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_set, test_set = train_test_split(heartbeat, test_size=0.3)\n",
    "train_set.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2388, 81)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common imports\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separate the target variable (we don't want to transform it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = train_set[['Target']]\n",
    "test_y = test_set[['Target']]\n",
    "\n",
    "train_x = train_set.drop(['Target'], axis=1)\n",
    "test_x = test_set.drop(['Target'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Target variables need to be an array with integer type\n",
    "train_y = np.array(train_y)\n",
    "test_y = np.array(test_y)\n",
    "\n",
    "train_y = train_y.astype(np.int32)\n",
    "test_y = test_y.astype(np.int32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [0],\n",
       "       [2],\n",
       "       [0],\n",
       "       [2],\n",
       "       [2],\n",
       "       [0],\n",
       "       [0],\n",
       "       [4],\n",
       "       [4]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check the first 10 values of the train_y data set\n",
    "train_y[0:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert input variables to a 2-D array with float data type\n",
    "train_x= np.array(train_x)\n",
    "test_x= np.array(test_x)\n",
    "\n",
    "train_x = train_x.astype(np.float32)\n",
    "test_x = test_x.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.    , 0.818 , 0.133 , ..., 0.354 , 0.354 , 0.387 ],\n",
       "       [1.    , 0.849 , 0.166 , ..., 0.108 , 0.0811, 0.0695],\n",
       "       [0.    , 0.0335, 0.163 , ..., 0.62  , 0.624 , 0.606 ],\n",
       "       ...,\n",
       "       [1.    , 0.98  , 0.573 , ..., 0.057 , 0.038 , 0.0418],\n",
       "       [0.564 , 0.512 , 0.468 , ..., 0.357 , 0.348 , 0.354 ],\n",
       "       [0.799 , 0.683 , 0.564 , ..., 0.265 , 0.265 , 0.247 ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Keras expects a different input format:\n",
    "#Data needs to have 3 dimensions\n",
    "\n",
    "train_x = np.reshape(train_x, (train_x.shape[0], train_x.shape[1], 1))\n",
    "test_x = np.reshape(test_x, (test_x.shape[0], test_x.shape[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5572, 80, 1), (5572, 1), (2388, 80, 1), (2388, 1))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape, train_y.shape, test_x.shape, test_y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find the baseline (0.5 point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Target\n",
       "0         0.582035\n",
       "4         0.198995\n",
       "2         0.155402\n",
       "1         0.055905\n",
       "3         0.007663\n",
       "dtype: float64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heartbeat[['Target']].value_counts()/len(heartbeat[['Target']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5572, 80, 1)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#What is your input shape?\n",
    "#(meaning: how many neurons should be in the input layer?)\n",
    "\n",
    "train_x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a cross-sectional shallow model using Keras (with only one hidden layer) (2 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the model: for multi-class\n",
    "model = keras.models.Sequential([\n",
    "    \n",
    "    keras.layers.Flatten(input_shape=[80, 1]),\n",
    "    keras.layers.Dense(80, activation='relu'),\n",
    "    keras.layers.Dense(5, activation='softmax')\n",
    "    \n",
    "])\n",
    "#final layer: there has to be 5 nodes with softmax (because we have 5 categories)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "175/175 [==============================] - 1s 1ms/step - loss: 0.6945 - accuracy: 0.7656 - val_loss: 0.6032 - val_accuracy: 0.8250\n",
      "Epoch 2/50\n",
      "175/175 [==============================] - 0s 765us/step - loss: 0.4629 - accuracy: 0.8471 - val_loss: 0.4533 - val_accuracy: 0.8413\n",
      "Epoch 3/50\n",
      "175/175 [==============================] - 0s 759us/step - loss: 0.3923 - accuracy: 0.8753 - val_loss: 1.0576 - val_accuracy: 0.5879\n",
      "Epoch 4/50\n",
      "175/175 [==============================] - 0s 736us/step - loss: 0.3649 - accuracy: 0.8855 - val_loss: 0.4029 - val_accuracy: 0.8601\n",
      "Epoch 5/50\n",
      "175/175 [==============================] - 0s 747us/step - loss: 0.3300 - accuracy: 0.8981 - val_loss: 0.2963 - val_accuracy: 0.9150\n",
      "Epoch 6/50\n",
      "175/175 [==============================] - 0s 742us/step - loss: 0.3093 - accuracy: 0.9063 - val_loss: 0.8719 - val_accuracy: 0.7513\n",
      "Epoch 7/50\n",
      "175/175 [==============================] - 0s 730us/step - loss: 0.3021 - accuracy: 0.9061 - val_loss: 0.4390 - val_accuracy: 0.8585\n",
      "Epoch 8/50\n",
      "175/175 [==============================] - 0s 747us/step - loss: 0.2813 - accuracy: 0.9119 - val_loss: 0.4289 - val_accuracy: 0.8580\n",
      "Epoch 9/50\n",
      "175/175 [==============================] - 0s 788us/step - loss: 0.2703 - accuracy: 0.9164 - val_loss: 0.6761 - val_accuracy: 0.7864\n",
      "Epoch 10/50\n",
      "175/175 [==============================] - 0s 759us/step - loss: 0.2603 - accuracy: 0.9174 - val_loss: 0.3031 - val_accuracy: 0.9037\n",
      "Epoch 11/50\n",
      "175/175 [==============================] - 0s 765us/step - loss: 0.2468 - accuracy: 0.9226 - val_loss: 0.2599 - val_accuracy: 0.9217\n",
      "Epoch 12/50\n",
      "175/175 [==============================] - 0s 765us/step - loss: 0.2377 - accuracy: 0.9261 - val_loss: 0.5486 - val_accuracy: 0.8446\n",
      "Epoch 13/50\n",
      "175/175 [==============================] - 0s 770us/step - loss: 0.2277 - accuracy: 0.9300 - val_loss: 0.2368 - val_accuracy: 0.9363\n",
      "Epoch 14/50\n",
      "175/175 [==============================] - 0s 776us/step - loss: 0.2191 - accuracy: 0.9316 - val_loss: 0.3288 - val_accuracy: 0.9087\n",
      "Epoch 15/50\n",
      "175/175 [==============================] - 0s 759us/step - loss: 0.2225 - accuracy: 0.9300 - val_loss: 0.6849 - val_accuracy: 0.8220\n",
      "Epoch 16/50\n",
      "175/175 [==============================] - 0s 788us/step - loss: 0.2071 - accuracy: 0.9374 - val_loss: 0.2306 - val_accuracy: 0.9372\n",
      "Epoch 17/50\n",
      "175/175 [==============================] - 0s 782us/step - loss: 0.2068 - accuracy: 0.9332 - val_loss: 0.2391 - val_accuracy: 0.9305\n",
      "Epoch 18/50\n",
      "175/175 [==============================] - 0s 770us/step - loss: 0.2005 - accuracy: 0.9368 - val_loss: 0.2649 - val_accuracy: 0.9192\n",
      "Epoch 19/50\n",
      "175/175 [==============================] - 0s 770us/step - loss: 0.1918 - accuracy: 0.9381 - val_loss: 1.6374 - val_accuracy: 0.5737\n",
      "Epoch 20/50\n",
      "175/175 [==============================] - 0s 770us/step - loss: 0.2097 - accuracy: 0.9316 - val_loss: 0.2273 - val_accuracy: 0.9384\n",
      "Epoch 21/50\n",
      "175/175 [==============================] - 0s 770us/step - loss: 0.1889 - accuracy: 0.9408 - val_loss: 0.2372 - val_accuracy: 0.9351\n",
      "Epoch 22/50\n",
      "175/175 [==============================] - 0s 770us/step - loss: 0.1840 - accuracy: 0.9458 - val_loss: 0.4246 - val_accuracy: 0.8551\n",
      "Epoch 23/50\n",
      "175/175 [==============================] - 0s 776us/step - loss: 0.1849 - accuracy: 0.9419 - val_loss: 0.2418 - val_accuracy: 0.9334\n",
      "Epoch 24/50\n",
      "175/175 [==============================] - 0s 816us/step - loss: 0.1862 - accuracy: 0.9384 - val_loss: 0.2415 - val_accuracy: 0.9326\n",
      "Epoch 25/50\n",
      "175/175 [==============================] - 0s 776us/step - loss: 0.1806 - accuracy: 0.9392 - val_loss: 0.2338 - val_accuracy: 0.9313\n",
      "Epoch 26/50\n",
      "175/175 [==============================] - 0s 753us/step - loss: 0.1707 - accuracy: 0.9463 - val_loss: 0.2213 - val_accuracy: 0.9405\n",
      "Epoch 27/50\n",
      "175/175 [==============================] - 0s 753us/step - loss: 0.1698 - accuracy: 0.9476 - val_loss: 0.2257 - val_accuracy: 0.9368\n",
      "Epoch 28/50\n",
      "175/175 [==============================] - 0s 750us/step - loss: 0.1699 - accuracy: 0.9456 - val_loss: 0.2105 - val_accuracy: 0.9426\n",
      "Epoch 29/50\n",
      "175/175 [==============================] - 0s 765us/step - loss: 0.1664 - accuracy: 0.9469 - val_loss: 0.2782 - val_accuracy: 0.9200\n",
      "Epoch 30/50\n",
      "175/175 [==============================] - 0s 759us/step - loss: 0.1726 - accuracy: 0.9469 - val_loss: 0.2401 - val_accuracy: 0.9363\n",
      "Epoch 31/50\n",
      "175/175 [==============================] - 0s 742us/step - loss: 0.1624 - accuracy: 0.9467 - val_loss: 0.2446 - val_accuracy: 0.9359\n",
      "Epoch 32/50\n",
      "175/175 [==============================] - 0s 742us/step - loss: 0.1648 - accuracy: 0.9471 - val_loss: 0.2569 - val_accuracy: 0.9338\n",
      "Epoch 33/50\n",
      "175/175 [==============================] - 0s 736us/step - loss: 0.1682 - accuracy: 0.9485 - val_loss: 0.4439 - val_accuracy: 0.8509\n",
      "Epoch 34/50\n",
      "175/175 [==============================] - 0s 776us/step - loss: 0.1685 - accuracy: 0.9422 - val_loss: 0.2280 - val_accuracy: 0.9363\n",
      "Epoch 35/50\n",
      "175/175 [==============================] - 0s 857us/step - loss: 0.1567 - accuracy: 0.9499 - val_loss: 0.2488 - val_accuracy: 0.9330\n",
      "Epoch 36/50\n",
      "175/175 [==============================] - 0s 799us/step - loss: 0.1519 - accuracy: 0.9526 - val_loss: 0.2845 - val_accuracy: 0.9192\n",
      "Epoch 37/50\n",
      "175/175 [==============================] - 0s 788us/step - loss: 0.1494 - accuracy: 0.9530 - val_loss: 0.2165 - val_accuracy: 0.9477\n",
      "Epoch 38/50\n",
      "175/175 [==============================] - 0s 960us/step - loss: 0.1513 - accuracy: 0.9497 - val_loss: 0.2516 - val_accuracy: 0.9271\n",
      "Epoch 39/50\n",
      "175/175 [==============================] - 0s 753us/step - loss: 0.1537 - accuracy: 0.9533 - val_loss: 0.2877 - val_accuracy: 0.9322\n",
      "Epoch 40/50\n",
      "175/175 [==============================] - 0s 747us/step - loss: 0.1528 - accuracy: 0.9508 - val_loss: 0.2203 - val_accuracy: 0.9430\n",
      "Epoch 41/50\n",
      "175/175 [==============================] - 0s 782us/step - loss: 0.1420 - accuracy: 0.9532 - val_loss: 0.2298 - val_accuracy: 0.9359\n",
      "Epoch 42/50\n",
      "175/175 [==============================] - 0s 908us/step - loss: 0.1497 - accuracy: 0.9506 - val_loss: 0.2399 - val_accuracy: 0.9422\n",
      "Epoch 43/50\n",
      "175/175 [==============================] - 0s 822us/step - loss: 0.1441 - accuracy: 0.9512 - val_loss: 0.3179 - val_accuracy: 0.9116\n",
      "Epoch 44/50\n",
      "175/175 [==============================] - 0s 788us/step - loss: 0.1608 - accuracy: 0.9480 - val_loss: 0.2538 - val_accuracy: 0.9376\n",
      "Epoch 45/50\n",
      "175/175 [==============================] - 0s 793us/step - loss: 0.1493 - accuracy: 0.9523 - val_loss: 0.2197 - val_accuracy: 0.9414\n",
      "Epoch 46/50\n",
      "175/175 [==============================] - 0s 776us/step - loss: 0.1423 - accuracy: 0.9533 - val_loss: 0.2285 - val_accuracy: 0.9393\n",
      "Epoch 47/50\n",
      "175/175 [==============================] - 0s 770us/step - loss: 0.1451 - accuracy: 0.9503 - val_loss: 0.2794 - val_accuracy: 0.9326\n",
      "Epoch 48/50\n",
      "175/175 [==============================] - 0s 776us/step - loss: 0.1487 - accuracy: 0.9532 - val_loss: 0.2228 - val_accuracy: 0.9426\n",
      "Epoch 49/50\n",
      "175/175 [==============================] - 0s 793us/step - loss: 0.1374 - accuracy: 0.9576 - val_loss: 0.2450 - val_accuracy: 0.9368\n",
      "Epoch 50/50\n",
      "175/175 [==============================] - 0s 770us/step - loss: 0.1387 - accuracy: 0.9541 - val_loss: 0.2163 - val_accuracy: 0.9447\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Nadam(learning_rate=0.01)\n",
    "\n",
    "# If multiclass, use \"sparse_categorical_crossentropy\" as the loss function\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "\n",
    "history = model.fit(train_x, train_y, epochs=50,\n",
    "                    validation_data=(test_x, test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.11406494677066803, 0.9628499746322632]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate the model\n",
    "scores_train = model.evaluate(train_x, train_y, verbose=0)\n",
    "scores_test = model.evaluate(test_x, test_y, verbose=0)\n",
    "scores_train\n",
    "\n",
    "\n",
    "# In results, first is loss, second is accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.21628998219966888, 0.9447236061096191]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.11\n",
      "accuracy: 96.28%\n",
      "loss: 0.22\n",
      "accuracy: 94.47%\n"
     ]
    }
   ],
   "source": [
    "# extract the accuracy from model.evaluate\n",
    "\n",
    "# extract the accuracy from model.evaluate\n",
    "print(\"%s: %.2f\" % (model.metrics_names[0], scores_train[0]))\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores_train[1]*100))\n",
    "print(\"%s: %.2f\" % (model.metrics_names[0], scores_test[0]))\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores_test[1]*100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a cross-sectional deep model using Keras (with two or more hidden layers) (2 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the model: for multi-class\n",
    "model = keras.models.Sequential([\n",
    "    \n",
    "    keras.layers.Flatten(input_shape=[80, 1]),\n",
    "    keras.layers.Dense(80, activation='relu'),\n",
    "    keras.layers.Dense(80, activation='relu'),\n",
    "    keras.layers.Dense(80, activation='relu'),\n",
    "    keras.layers.Dense(5, activation='softmax')\n",
    "    \n",
    "])\n",
    "#final layer: there has to be 5 nodes with softmax (because we have 5 categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "175/175 [==============================] - 1s 1ms/step - loss: 0.7080 - accuracy: 0.7484 - val_loss: 0.4619 - val_accuracy: 0.8291\n",
      "Epoch 2/50\n",
      "175/175 [==============================] - 0s 874us/step - loss: 0.4552 - accuracy: 0.8410 - val_loss: 0.6547 - val_accuracy: 0.7312\n",
      "Epoch 3/50\n",
      "175/175 [==============================] - 0s 891us/step - loss: 0.3817 - accuracy: 0.8798 - val_loss: 0.5792 - val_accuracy: 0.8199\n",
      "Epoch 4/50\n",
      "175/175 [==============================] - 0s 903us/step - loss: 0.3660 - accuracy: 0.8824 - val_loss: 0.3810 - val_accuracy: 0.8794\n",
      "Epoch 5/50\n",
      "175/175 [==============================] - 0s 851us/step - loss: 0.3313 - accuracy: 0.8957 - val_loss: 0.2701 - val_accuracy: 0.9255\n",
      "Epoch 6/50\n",
      "175/175 [==============================] - 0s 891us/step - loss: 0.2903 - accuracy: 0.9092 - val_loss: 0.8484 - val_accuracy: 0.8287\n",
      "Epoch 7/50\n",
      "175/175 [==============================] - 0s 885us/step - loss: 0.2932 - accuracy: 0.9085 - val_loss: 0.5405 - val_accuracy: 0.8329\n",
      "Epoch 8/50\n",
      "175/175 [==============================] - 0s 851us/step - loss: 0.2678 - accuracy: 0.9178 - val_loss: 0.2868 - val_accuracy: 0.9121\n",
      "Epoch 9/50\n",
      "175/175 [==============================] - 0s 874us/step - loss: 0.2539 - accuracy: 0.9196 - val_loss: 0.3123 - val_accuracy: 0.9121\n",
      "Epoch 10/50\n",
      "175/175 [==============================] - 0s 948us/step - loss: 0.2419 - accuracy: 0.9255 - val_loss: 0.6355 - val_accuracy: 0.7902\n",
      "Epoch 11/50\n",
      "175/175 [==============================] - 0s 885us/step - loss: 0.2519 - accuracy: 0.9232 - val_loss: 0.2297 - val_accuracy: 0.9330\n",
      "Epoch 12/50\n",
      "175/175 [==============================] - 0s 862us/step - loss: 0.2241 - accuracy: 0.9288 - val_loss: 0.4320 - val_accuracy: 0.8878\n",
      "Epoch 13/50\n",
      "175/175 [==============================] - 0s 857us/step - loss: 0.2240 - accuracy: 0.9293 - val_loss: 0.2241 - val_accuracy: 0.9368\n",
      "Epoch 14/50\n",
      "175/175 [==============================] - 0s 880us/step - loss: 0.2264 - accuracy: 0.9282 - val_loss: 0.2329 - val_accuracy: 0.9234\n",
      "Epoch 15/50\n",
      "175/175 [==============================] - 0s 885us/step - loss: 0.2094 - accuracy: 0.9329 - val_loss: 0.2092 - val_accuracy: 0.9380\n",
      "Epoch 16/50\n",
      "175/175 [==============================] - 0s 862us/step - loss: 0.1967 - accuracy: 0.9363 - val_loss: 0.2229 - val_accuracy: 0.9288\n",
      "Epoch 17/50\n",
      "175/175 [==============================] - 0s 857us/step - loss: 0.1892 - accuracy: 0.9404 - val_loss: 0.2089 - val_accuracy: 0.9401\n",
      "Epoch 18/50\n",
      "175/175 [==============================] - 0s 851us/step - loss: 0.1844 - accuracy: 0.9413 - val_loss: 0.2273 - val_accuracy: 0.9380\n",
      "Epoch 19/50\n",
      "175/175 [==============================] - 0s 862us/step - loss: 0.1855 - accuracy: 0.9426 - val_loss: 0.3316 - val_accuracy: 0.9003\n",
      "Epoch 20/50\n",
      "175/175 [==============================] - 0s 839us/step - loss: 0.1925 - accuracy: 0.9375 - val_loss: 0.2060 - val_accuracy: 0.9380\n",
      "Epoch 21/50\n",
      "175/175 [==============================] - 0s 851us/step - loss: 0.1746 - accuracy: 0.9419 - val_loss: 0.2538 - val_accuracy: 0.9338\n",
      "Epoch 22/50\n",
      "175/175 [==============================] - 0s 897us/step - loss: 0.1751 - accuracy: 0.9444 - val_loss: 0.1991 - val_accuracy: 0.9414\n",
      "Epoch 23/50\n",
      "175/175 [==============================] - 0s 902us/step - loss: 0.1689 - accuracy: 0.9445 - val_loss: 0.2289 - val_accuracy: 0.9267\n",
      "Epoch 24/50\n",
      "175/175 [==============================] - 0s 891us/step - loss: 0.1711 - accuracy: 0.9453 - val_loss: 0.2268 - val_accuracy: 0.9355\n",
      "Epoch 25/50\n",
      "175/175 [==============================] - 0s 908us/step - loss: 0.1686 - accuracy: 0.9442 - val_loss: 0.2330 - val_accuracy: 0.9376\n",
      "Epoch 26/50\n",
      "175/175 [==============================] - 0s 891us/step - loss: 0.1757 - accuracy: 0.9462 - val_loss: 0.3331 - val_accuracy: 0.9112\n",
      "Epoch 27/50\n",
      "175/175 [==============================] - 0s 908us/step - loss: 0.1934 - accuracy: 0.9381 - val_loss: 0.2184 - val_accuracy: 0.9330\n",
      "Epoch 28/50\n",
      "175/175 [==============================] - 0s 900us/step - loss: 0.1824 - accuracy: 0.9419 - val_loss: 0.2137 - val_accuracy: 0.9334\n",
      "Epoch 29/50\n",
      "175/175 [==============================] - 0s 897us/step - loss: 0.1555 - accuracy: 0.9485 - val_loss: 0.2473 - val_accuracy: 0.9322\n",
      "Epoch 30/50\n",
      "175/175 [==============================] - 0s 954us/step - loss: 0.1473 - accuracy: 0.9539 - val_loss: 0.2307 - val_accuracy: 0.9322\n",
      "Epoch 31/50\n",
      "175/175 [==============================] - 0s 914us/step - loss: 0.1700 - accuracy: 0.9417 - val_loss: 0.4712 - val_accuracy: 0.8894\n",
      "Epoch 32/50\n",
      "175/175 [==============================] - 0s 914us/step - loss: 0.2087 - accuracy: 0.9345 - val_loss: 0.3023 - val_accuracy: 0.9104\n",
      "Epoch 33/50\n",
      "175/175 [==============================] - 0s 943us/step - loss: 0.1665 - accuracy: 0.9492 - val_loss: 0.2367 - val_accuracy: 0.9326\n",
      "Epoch 34/50\n",
      "175/175 [==============================] - 0s 940us/step - loss: 0.1481 - accuracy: 0.9530 - val_loss: 0.2714 - val_accuracy: 0.9255\n",
      "Epoch 35/50\n",
      "175/175 [==============================] - 0s 920us/step - loss: 0.1459 - accuracy: 0.9526 - val_loss: 0.2275 - val_accuracy: 0.9292\n",
      "Epoch 36/50\n",
      "175/175 [==============================] - 0s 926us/step - loss: 0.1408 - accuracy: 0.9566 - val_loss: 0.2254 - val_accuracy: 0.9343\n",
      "Epoch 37/50\n",
      "175/175 [==============================] - 0s 937us/step - loss: 0.1432 - accuracy: 0.9537 - val_loss: 1.8393 - val_accuracy: 0.6085\n",
      "Epoch 38/50\n",
      "175/175 [==============================] - 0s 943us/step - loss: 0.3031 - accuracy: 0.9110 - val_loss: 0.2203 - val_accuracy: 0.9368\n",
      "Epoch 39/50\n",
      "175/175 [==============================] - 0s 954us/step - loss: 0.1926 - accuracy: 0.9440 - val_loss: 0.2098 - val_accuracy: 0.9456\n",
      "Epoch 40/50\n",
      "175/175 [==============================] - 0s 931us/step - loss: 0.1606 - accuracy: 0.9485 - val_loss: 0.2996 - val_accuracy: 0.9209\n",
      "Epoch 41/50\n",
      "175/175 [==============================] - 0s 943us/step - loss: 0.1742 - accuracy: 0.9454 - val_loss: 0.2159 - val_accuracy: 0.9451\n",
      "Epoch 42/50\n",
      "175/175 [==============================] - 0s 931us/step - loss: 0.1430 - accuracy: 0.9544 - val_loss: 0.2124 - val_accuracy: 0.9430\n",
      "Epoch 43/50\n",
      "175/175 [==============================] - 0s 960us/step - loss: 0.1486 - accuracy: 0.9524 - val_loss: 0.2045 - val_accuracy: 0.9439\n",
      "Epoch 44/50\n",
      "175/175 [==============================] - 0s 954us/step - loss: 0.1325 - accuracy: 0.9573 - val_loss: 0.1975 - val_accuracy: 0.9481\n",
      "Epoch 45/50\n",
      "175/175 [==============================] - 0s 943us/step - loss: 0.1525 - accuracy: 0.9535 - val_loss: 0.2157 - val_accuracy: 0.9435\n",
      "Epoch 46/50\n",
      "175/175 [==============================] - 0s 943us/step - loss: 0.1409 - accuracy: 0.9562 - val_loss: 0.2297 - val_accuracy: 0.9397\n",
      "Epoch 47/50\n",
      "175/175 [==============================] - 0s 943us/step - loss: 0.1320 - accuracy: 0.9582 - val_loss: 0.2046 - val_accuracy: 0.9418\n",
      "Epoch 48/50\n",
      "175/175 [==============================] - 0s 937us/step - loss: 0.1309 - accuracy: 0.9560 - val_loss: 0.2454 - val_accuracy: 0.9351\n",
      "Epoch 49/50\n",
      "175/175 [==============================] - 0s 937us/step - loss: 0.1400 - accuracy: 0.9550 - val_loss: 0.2018 - val_accuracy: 0.9472\n",
      "Epoch 50/50\n",
      "175/175 [==============================] - 0s 937us/step - loss: 0.1524 - accuracy: 0.9528 - val_loss: 0.2188 - val_accuracy: 0.9443\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Nadam(learning_rate=0.01)\n",
    "\n",
    "# If multiclass, use \"sparse_categorical_crossentropy\" as the loss function\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "\n",
    "history = model.fit(train_x, train_y, epochs=50,\n",
    "                    validation_data=(test_x, test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.13569949567317963, 0.9574658870697021]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate the model\n",
    "scores_train = model.evaluate(train_x, train_y, verbose=0)\n",
    "scores_test = model.evaluate(test_x, test_y, verbose=0)\n",
    "scores_train\n",
    "\n",
    "# In results, first is loss, second is accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.21879437565803528, 0.944304883480072]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.14\n",
      "accuracy: 95.75%\n",
      "loss: 0.22\n",
      "accuracy: 94.43%\n"
     ]
    }
   ],
   "source": [
    "# extract the accuracy from model.evaluate\n",
    "\n",
    "# extract the accuracy from model.evaluate\n",
    "print(\"%s: %.2f\" % (model.metrics_names[0], scores_train[0]))\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores_train[1]*100))\n",
    "print(\"%s: %.2f\" % (model.metrics_names[0], scores_test[0]))\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores_test[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a sequential shallow LSTM Model (with only one LSTM layer) (2 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = 80\n",
    "n_inputs = 1\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    \n",
    "    keras.layers.LSTM(5, activation='softmax' , input_shape=[n_steps, n_inputs])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "\n",
    "earlystop = EarlyStopping(monitor='val_loss', patience=5, verbose=1, mode='auto')\n",
    "\n",
    "callback = [earlystop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "175/175 [==============================] - 3s 12ms/step - loss: 1.1816 - accuracy: 0.5777 - val_loss: 1.0490 - val_accuracy: 0.5984\n",
      "Epoch 2/50\n",
      "175/175 [==============================] - 2s 11ms/step - loss: 1.0640 - accuracy: 0.5926 - val_loss: 1.0549 - val_accuracy: 0.5942\n",
      "Epoch 3/50\n",
      "175/175 [==============================] - 2s 12ms/step - loss: 1.0562 - accuracy: 0.6012 - val_loss: 1.0607 - val_accuracy: 0.6051\n",
      "Epoch 4/50\n",
      "175/175 [==============================] - 2s 12ms/step - loss: 1.0492 - accuracy: 0.6034 - val_loss: 1.0471 - val_accuracy: 0.6160\n",
      "Epoch 5/50\n",
      "175/175 [==============================] - 2s 12ms/step - loss: 1.0443 - accuracy: 0.6079 - val_loss: 1.0754 - val_accuracy: 0.5637\n",
      "Epoch 6/50\n",
      "175/175 [==============================] - 2s 12ms/step - loss: 1.0401 - accuracy: 0.6138 - val_loss: 1.0218 - val_accuracy: 0.6118\n",
      "Epoch 7/50\n",
      "175/175 [==============================] - 2s 12ms/step - loss: 1.0361 - accuracy: 0.6143 - val_loss: 1.0140 - val_accuracy: 0.6185\n",
      "Epoch 8/50\n",
      "175/175 [==============================] - 2s 12ms/step - loss: 1.0319 - accuracy: 0.6132 - val_loss: 1.1182 - val_accuracy: 0.5532\n",
      "Epoch 9/50\n",
      "175/175 [==============================] - 2s 11ms/step - loss: 1.0260 - accuracy: 0.6201 - val_loss: 0.9998 - val_accuracy: 0.6269\n",
      "Epoch 10/50\n",
      "175/175 [==============================] - 2s 11ms/step - loss: 1.0145 - accuracy: 0.6292 - val_loss: 1.0074 - val_accuracy: 0.6260\n",
      "Epoch 11/50\n",
      "175/175 [==============================] - 2s 11ms/step - loss: 1.0041 - accuracy: 0.6296 - val_loss: 0.9943 - val_accuracy: 0.6189\n",
      "Epoch 12/50\n",
      "175/175 [==============================] - 2s 11ms/step - loss: 0.9900 - accuracy: 0.6317 - val_loss: 0.9964 - val_accuracy: 0.6365\n",
      "Epoch 13/50\n",
      "175/175 [==============================] - 2s 11ms/step - loss: 0.9765 - accuracy: 0.6420 - val_loss: 0.9909 - val_accuracy: 0.6064\n",
      "Epoch 14/50\n",
      "175/175 [==============================] - 2s 11ms/step - loss: 0.9648 - accuracy: 0.6497 - val_loss: 0.9880 - val_accuracy: 0.6265\n",
      "Epoch 15/50\n",
      "175/175 [==============================] - 2s 11ms/step - loss: 0.9441 - accuracy: 0.6601 - val_loss: 0.9936 - val_accuracy: 0.6168\n",
      "Epoch 16/50\n",
      "175/175 [==============================] - 2s 11ms/step - loss: 0.9294 - accuracy: 0.6572 - val_loss: 0.9302 - val_accuracy: 0.6361\n",
      "Epoch 17/50\n",
      "175/175 [==============================] - 2s 11ms/step - loss: 0.9106 - accuracy: 0.6674 - val_loss: 0.8775 - val_accuracy: 0.6616\n",
      "Epoch 18/50\n",
      "175/175 [==============================] - 2s 11ms/step - loss: 0.8913 - accuracy: 0.6780 - val_loss: 0.8577 - val_accuracy: 0.6809\n",
      "Epoch 19/50\n",
      "175/175 [==============================] - 2s 11ms/step - loss: 0.8772 - accuracy: 0.6829 - val_loss: 0.9764 - val_accuracy: 0.6478\n",
      "Epoch 20/50\n",
      "175/175 [==============================] - 2s 11ms/step - loss: 0.8634 - accuracy: 0.6890 - val_loss: 0.8550 - val_accuracy: 0.6838\n",
      "Epoch 21/50\n",
      "175/175 [==============================] - 2s 11ms/step - loss: 0.8549 - accuracy: 0.6951 - val_loss: 0.8283 - val_accuracy: 0.7048\n",
      "Epoch 22/50\n",
      "175/175 [==============================] - 2s 11ms/step - loss: 0.8498 - accuracy: 0.6945 - val_loss: 0.8280 - val_accuracy: 0.6922\n",
      "Epoch 23/50\n",
      "175/175 [==============================] - 2s 11ms/step - loss: 0.8433 - accuracy: 0.6963 - val_loss: 0.8264 - val_accuracy: 0.7018\n",
      "Epoch 24/50\n",
      "175/175 [==============================] - 2s 11ms/step - loss: 0.8372 - accuracy: 0.6956 - val_loss: 0.8566 - val_accuracy: 0.6671\n",
      "Epoch 25/50\n",
      "175/175 [==============================] - 2s 11ms/step - loss: 0.8386 - accuracy: 0.6956 - val_loss: 0.8080 - val_accuracy: 0.7023\n",
      "Epoch 26/50\n",
      "175/175 [==============================] - 2s 11ms/step - loss: 0.8311 - accuracy: 0.7019 - val_loss: 0.8221 - val_accuracy: 0.6951\n",
      "Epoch 27/50\n",
      "175/175 [==============================] - 2s 11ms/step - loss: 0.8290 - accuracy: 0.6976 - val_loss: 0.8105 - val_accuracy: 0.7010\n",
      "Epoch 28/50\n",
      "175/175 [==============================] - 2s 11ms/step - loss: 0.8231 - accuracy: 0.7028 - val_loss: 0.8472 - val_accuracy: 0.6914\n",
      "Epoch 29/50\n",
      "175/175 [==============================] - 2s 11ms/step - loss: 0.8264 - accuracy: 0.6971 - val_loss: 0.8048 - val_accuracy: 0.7060\n",
      "Epoch 30/50\n",
      "175/175 [==============================] - 2s 11ms/step - loss: 0.8180 - accuracy: 0.7017 - val_loss: 0.8697 - val_accuracy: 0.6361\n",
      "Epoch 31/50\n",
      "175/175 [==============================] - 2s 11ms/step - loss: 0.8160 - accuracy: 0.7093 - val_loss: 0.8216 - val_accuracy: 0.6809\n",
      "Epoch 32/50\n",
      "175/175 [==============================] - 2s 11ms/step - loss: 0.8149 - accuracy: 0.7051 - val_loss: 0.7938 - val_accuracy: 0.6943\n",
      "Epoch 33/50\n",
      "175/175 [==============================] - 2s 11ms/step - loss: 0.8064 - accuracy: 0.7112 - val_loss: 0.7886 - val_accuracy: 0.7060\n",
      "Epoch 34/50\n",
      "175/175 [==============================] - 2s 11ms/step - loss: 0.8062 - accuracy: 0.7141 - val_loss: 0.7765 - val_accuracy: 0.7194\n",
      "Epoch 35/50\n",
      "175/175 [==============================] - 2s 11ms/step - loss: 0.8053 - accuracy: 0.7116 - val_loss: 0.7922 - val_accuracy: 0.7194\n",
      "Epoch 36/50\n",
      "175/175 [==============================] - 2s 11ms/step - loss: 0.8006 - accuracy: 0.7148 - val_loss: 0.7843 - val_accuracy: 0.7002\n",
      "Epoch 37/50\n",
      "175/175 [==============================] - 2s 11ms/step - loss: 0.8022 - accuracy: 0.7102 - val_loss: 1.0047 - val_accuracy: 0.6294\n",
      "Epoch 38/50\n",
      "175/175 [==============================] - 2s 11ms/step - loss: 0.8001 - accuracy: 0.7128 - val_loss: 0.7954 - val_accuracy: 0.6889\n",
      "Epoch 39/50\n",
      "175/175 [==============================] - 2s 11ms/step - loss: 0.7946 - accuracy: 0.7139 - val_loss: 0.7786 - val_accuracy: 0.7144\n",
      "Epoch 39: early stopping\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "optimizer = keras.optimizers.Nadam(learning_rate=0.01)\n",
    "\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(train_x, train_y, epochs=50,\n",
    "                   validation_data = (test_x, test_y), callbacks=callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7786266207695007, 0.714405357837677]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate the model\n",
    "\n",
    "scores = model.evaluate(test_x, test_y, verbose=0)\n",
    "\n",
    "scores\n",
    "\n",
    "# In results, first is loss, second is accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.78\n",
      "accuracy: 71.44%\n"
     ]
    }
   ],
   "source": [
    "# extract the accuracy from model.evaluate\n",
    "\n",
    "print(\"%s: %.2f\" % (model.metrics_names[0], scores[0]))\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a sequential deep LSTM Model (with only two LSTM layers) (2 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = 80\n",
    "n_inputs = 1\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.LSTM(5, return_sequences=True, input_shape=[n_steps, n_inputs]),\n",
    "    keras.layers.LSTM(5, return_sequences=False),\n",
    "    keras.layers.Dense(5, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "\n",
    "earlystop = EarlyStopping(monitor='val_loss', patience=5, verbose=1, mode='auto')\n",
    "\n",
    "callback = [earlystop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "175/175 [==============================] - 7s 26ms/step - loss: 1.0766 - accuracy: 0.6025 - val_loss: 0.9333 - val_accuracy: 0.6327\n",
      "Epoch 2/20\n",
      "175/175 [==============================] - 4s 24ms/step - loss: 0.9161 - accuracy: 0.6597 - val_loss: 1.0318 - val_accuracy: 0.6637\n",
      "Epoch 3/20\n",
      "175/175 [==============================] - 4s 24ms/step - loss: 0.8262 - accuracy: 0.7024 - val_loss: 1.5051 - val_accuracy: 0.3945\n",
      "Epoch 4/20\n",
      "175/175 [==============================] - 4s 24ms/step - loss: 0.8161 - accuracy: 0.7024 - val_loss: 0.7680 - val_accuracy: 0.7320\n",
      "Epoch 5/20\n",
      "175/175 [==============================] - 4s 24ms/step - loss: 0.7546 - accuracy: 0.7367 - val_loss: 0.9640 - val_accuracy: 0.6495\n",
      "Epoch 6/20\n",
      "175/175 [==============================] - 4s 24ms/step - loss: 0.7250 - accuracy: 0.7531 - val_loss: 1.2749 - val_accuracy: 0.5034\n",
      "Epoch 7/20\n",
      "175/175 [==============================] - 4s 24ms/step - loss: 0.6810 - accuracy: 0.7703 - val_loss: 0.7073 - val_accuracy: 0.7374\n",
      "Epoch 8/20\n",
      "175/175 [==============================] - 4s 24ms/step - loss: 0.6680 - accuracy: 0.7723 - val_loss: 0.8346 - val_accuracy: 0.7169\n",
      "Epoch 9/20\n",
      "175/175 [==============================] - 4s 24ms/step - loss: 0.6419 - accuracy: 0.7861 - val_loss: 0.6016 - val_accuracy: 0.7956\n",
      "Epoch 10/20\n",
      "175/175 [==============================] - 4s 24ms/step - loss: 0.6155 - accuracy: 0.7880 - val_loss: 0.6069 - val_accuracy: 0.7936\n",
      "Epoch 11/20\n",
      "175/175 [==============================] - 4s 24ms/step - loss: 0.5937 - accuracy: 0.7990 - val_loss: 0.5632 - val_accuracy: 0.8053\n",
      "Epoch 12/20\n",
      "175/175 [==============================] - 4s 24ms/step - loss: 0.5821 - accuracy: 0.8065 - val_loss: 1.6065 - val_accuracy: 0.5281\n",
      "Epoch 13/20\n",
      "175/175 [==============================] - 4s 24ms/step - loss: 0.5613 - accuracy: 0.8157 - val_loss: 0.5115 - val_accuracy: 0.8497\n",
      "Epoch 14/20\n",
      "175/175 [==============================] - 4s 24ms/step - loss: 0.5335 - accuracy: 0.8247 - val_loss: 0.6702 - val_accuracy: 0.7789\n",
      "Epoch 15/20\n",
      "175/175 [==============================] - 4s 24ms/step - loss: 0.5077 - accuracy: 0.8340 - val_loss: 0.7088 - val_accuracy: 0.7399\n",
      "Epoch 16/20\n",
      "175/175 [==============================] - 4s 24ms/step - loss: 0.5007 - accuracy: 0.8419 - val_loss: 0.6852 - val_accuracy: 0.7588\n",
      "Epoch 17/20\n",
      "175/175 [==============================] - 4s 24ms/step - loss: 0.4815 - accuracy: 0.8444 - val_loss: 0.7661 - val_accuracy: 0.6993\n",
      "Epoch 18/20\n",
      "175/175 [==============================] - 4s 24ms/step - loss: 0.4696 - accuracy: 0.8498 - val_loss: 0.5301 - val_accuracy: 0.8312\n",
      "Epoch 18: early stopping\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "optimizer = keras.optimizers.Nadam(learning_rate=0.01)\n",
    "\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(train_x, train_y, epochs=20,\n",
    "                   validation_data = (test_x, test_y), callbacks=callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5301226377487183, 0.8312395215034485]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate the model\n",
    "\n",
    "scores = model.evaluate(test_x, test_y, verbose=0)\n",
    "\n",
    "scores\n",
    "\n",
    "# In results, first is loss, second is accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.53\n",
      "accuracy: 83.12%\n"
     ]
    }
   ],
   "source": [
    "# extract the accuracy from model.evaluate\n",
    "\n",
    "print(\"%s: %.2f\" % (model.metrics_names[0], scores[0]))\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a sequential shallow GRU Model (with only one GRU layer) (2 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = 80\n",
    "n_inputs = 1\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.GRU(2, input_shape=[n_steps, n_inputs]),\n",
    "    keras.layers.Dense(5, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "175/175 [==============================] - 4s 15ms/step - loss: 1.2040 - accuracy: 0.5556 - val_loss: 1.0889 - val_accuracy: 0.5930\n",
      "Epoch 2/20\n",
      "175/175 [==============================] - 2s 13ms/step - loss: 1.0703 - accuracy: 0.5743 - val_loss: 1.0254 - val_accuracy: 0.5921\n",
      "Epoch 3/20\n",
      "175/175 [==============================] - 2s 14ms/step - loss: 1.0322 - accuracy: 0.5829 - val_loss: 1.0441 - val_accuracy: 0.5930\n",
      "Epoch 4/20\n",
      "175/175 [==============================] - 2s 14ms/step - loss: 1.0221 - accuracy: 0.5831 - val_loss: 1.0014 - val_accuracy: 0.6135\n",
      "Epoch 5/20\n",
      "175/175 [==============================] - 2s 14ms/step - loss: 1.0188 - accuracy: 0.5992 - val_loss: 1.0270 - val_accuracy: 0.5854\n",
      "Epoch 6/20\n",
      "175/175 [==============================] - 3s 15ms/step - loss: 1.0175 - accuracy: 0.6129 - val_loss: 0.9967 - val_accuracy: 0.6164\n",
      "Epoch 7/20\n",
      "175/175 [==============================] - 2s 14ms/step - loss: 1.0161 - accuracy: 0.6161 - val_loss: 0.9959 - val_accuracy: 0.6235\n",
      "Epoch 8/20\n",
      "175/175 [==============================] - 2s 13ms/step - loss: 1.0156 - accuracy: 0.6219 - val_loss: 1.0028 - val_accuracy: 0.6101\n",
      "Epoch 9/20\n",
      "175/175 [==============================] - 2s 14ms/step - loss: 1.0146 - accuracy: 0.6222 - val_loss: 0.9896 - val_accuracy: 0.6173\n",
      "Epoch 10/20\n",
      "175/175 [==============================] - 2s 14ms/step - loss: 1.0121 - accuracy: 0.6226 - val_loss: 1.0010 - val_accuracy: 0.6240\n",
      "Epoch 11/20\n",
      "175/175 [==============================] - 2s 14ms/step - loss: 1.0103 - accuracy: 0.6233 - val_loss: 0.9865 - val_accuracy: 0.6252\n",
      "Epoch 12/20\n",
      "175/175 [==============================] - 2s 13ms/step - loss: 1.0072 - accuracy: 0.6210 - val_loss: 0.9898 - val_accuracy: 0.6193\n",
      "Epoch 13/20\n",
      "175/175 [==============================] - 2s 13ms/step - loss: 1.0060 - accuracy: 0.6220 - val_loss: 0.9846 - val_accuracy: 0.6265\n",
      "Epoch 14/20\n",
      "175/175 [==============================] - 3s 14ms/step - loss: 1.0045 - accuracy: 0.6242 - val_loss: 0.9827 - val_accuracy: 0.6273\n",
      "Epoch 15/20\n",
      "175/175 [==============================] - 2s 14ms/step - loss: 1.0036 - accuracy: 0.6210 - val_loss: 0.9808 - val_accuracy: 0.6210\n",
      "Epoch 16/20\n",
      "175/175 [==============================] - 2s 14ms/step - loss: 1.0027 - accuracy: 0.6233 - val_loss: 0.9819 - val_accuracy: 0.6202\n",
      "Epoch 17/20\n",
      "175/175 [==============================] - 2s 14ms/step - loss: 1.0016 - accuracy: 0.6253 - val_loss: 0.9817 - val_accuracy: 0.6160\n",
      "Epoch 18/20\n",
      "175/175 [==============================] - 2s 14ms/step - loss: 1.0005 - accuracy: 0.6220 - val_loss: 0.9787 - val_accuracy: 0.6277\n",
      "Epoch 19/20\n",
      "175/175 [==============================] - 2s 14ms/step - loss: 0.9999 - accuracy: 0.6242 - val_loss: 0.9845 - val_accuracy: 0.6273\n",
      "Epoch 20/20\n",
      "175/175 [==============================] - 2s 14ms/step - loss: 1.0003 - accuracy: 0.6235 - val_loss: 0.9777 - val_accuracy: 0.6281\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "optimizer = keras.optimizers.Nadam(learning_rate=0.01)\n",
    "\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(train_x, train_y, epochs=20,\n",
    "                   validation_data = (test_x, test_y), callbacks=callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9777449369430542, 0.6281406879425049]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate the model\n",
    "\n",
    "scores = model.evaluate(test_x, test_y, verbose=0)\n",
    "\n",
    "scores\n",
    "\n",
    "# In results, first is loss, second is accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.98\n",
      "accuracy: 62.81%\n"
     ]
    }
   ],
   "source": [
    "# extract the accuracy from model.evaluate\n",
    "\n",
    "print(\"%s: %.2f\" % (model.metrics_names[0], scores[0]))\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a sequential deep GRU Model (with only two GRU layers) (2 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = 80\n",
    "n_inputs = 1\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.GRU(2, return_sequences=True, input_shape=[n_steps, n_inputs]),\n",
    "    keras.layers.GRU(2, return_sequences=False),\n",
    "    keras.layers.Dense(5, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "175/175 [==============================] - 7s 30ms/step - loss: 1.2149 - accuracy: 0.5711 - val_loss: 1.1128 - val_accuracy: 0.5930\n",
      "Epoch 2/20\n",
      "175/175 [==============================] - 5s 27ms/step - loss: 1.1349 - accuracy: 0.5774 - val_loss: 1.1144 - val_accuracy: 0.5930\n",
      "Epoch 3/20\n",
      "175/175 [==============================] - 5s 28ms/step - loss: 1.1338 - accuracy: 0.5774 - val_loss: 1.1021 - val_accuracy: 0.5930\n",
      "Epoch 4/20\n",
      "175/175 [==============================] - 5s 27ms/step - loss: 1.0813 - accuracy: 0.5879 - val_loss: 1.0422 - val_accuracy: 0.6156\n",
      "Epoch 5/20\n",
      "175/175 [==============================] - 5s 28ms/step - loss: 1.0437 - accuracy: 0.6068 - val_loss: 1.0576 - val_accuracy: 0.5930\n",
      "Epoch 6/20\n",
      "175/175 [==============================] - 5s 28ms/step - loss: 1.0293 - accuracy: 0.6030 - val_loss: 1.0035 - val_accuracy: 0.6076\n",
      "Epoch 7/20\n",
      "175/175 [==============================] - 5s 28ms/step - loss: 1.0177 - accuracy: 0.6005 - val_loss: 0.9973 - val_accuracy: 0.6131\n",
      "Epoch 8/20\n",
      "175/175 [==============================] - 5s 28ms/step - loss: 1.0053 - accuracy: 0.6030 - val_loss: 1.0481 - val_accuracy: 0.5515\n",
      "Epoch 9/20\n",
      "175/175 [==============================] - 5s 28ms/step - loss: 0.9907 - accuracy: 0.6208 - val_loss: 0.9586 - val_accuracy: 0.6265\n",
      "Epoch 10/20\n",
      "175/175 [==============================] - 5s 28ms/step - loss: 0.9601 - accuracy: 0.6368 - val_loss: 0.9421 - val_accuracy: 0.6432\n",
      "Epoch 11/20\n",
      "175/175 [==============================] - 5s 28ms/step - loss: 0.9184 - accuracy: 0.6459 - val_loss: 0.8912 - val_accuracy: 0.6512\n",
      "Epoch 12/20\n",
      "175/175 [==============================] - 5s 29ms/step - loss: 0.8936 - accuracy: 0.6502 - val_loss: 1.2060 - val_accuracy: 0.5147\n",
      "Epoch 13/20\n",
      "175/175 [==============================] - 5s 29ms/step - loss: 0.8820 - accuracy: 0.6595 - val_loss: 1.0149 - val_accuracy: 0.5825\n",
      "Epoch 14/20\n",
      "175/175 [==============================] - 5s 30ms/step - loss: 0.8626 - accuracy: 0.6748 - val_loss: 0.8752 - val_accuracy: 0.6738\n",
      "Epoch 15/20\n",
      "175/175 [==============================] - 5s 30ms/step - loss: 0.8483 - accuracy: 0.6762 - val_loss: 1.0474 - val_accuracy: 0.5582\n",
      "Epoch 16/20\n",
      "175/175 [==============================] - 5s 31ms/step - loss: 0.8386 - accuracy: 0.6877 - val_loss: 0.8964 - val_accuracy: 0.6679\n",
      "Epoch 17/20\n",
      "175/175 [==============================] - 5s 30ms/step - loss: 0.8316 - accuracy: 0.6958 - val_loss: 0.9366 - val_accuracy: 0.6286\n",
      "Epoch 18/20\n",
      "175/175 [==============================] - 5s 30ms/step - loss: 0.8244 - accuracy: 0.7066 - val_loss: 0.8309 - val_accuracy: 0.7073\n",
      "Epoch 19/20\n",
      "175/175 [==============================] - 5s 31ms/step - loss: 0.8155 - accuracy: 0.7161 - val_loss: 0.8091 - val_accuracy: 0.7077\n",
      "Epoch 20/20\n",
      "175/175 [==============================] - 5s 29ms/step - loss: 0.8114 - accuracy: 0.7204 - val_loss: 0.8199 - val_accuracy: 0.7023\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "optimizer = keras.optimizers.Nadam(learning_rate=0.01)\n",
    "\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(train_x, train_y, epochs=20,\n",
    "                   validation_data = (test_x, test_y), callbacks=callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8198843598365784, 0.7022613286972046]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate the model\n",
    "\n",
    "scores = model.evaluate(test_x, test_y, verbose=0)\n",
    "\n",
    "scores\n",
    "\n",
    "# In results, first is loss, second is accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.82\n",
      "accuracy: 70.23%\n"
     ]
    }
   ],
   "source": [
    "# extract the accuracy from model.evaluate\n",
    "\n",
    "print(\"%s: %.2f\" % (model.metrics_names[0], scores[0]))\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List the test values of each model you built (0.5 points)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "cross-sectional shallow model with only one hidden layer : loss: 0.22,accuracy: 94.47%\n",
    "cross-sectional shallow model with two or more hidden layers : loss: 0.22, accuracy: 94.43%\n",
    "LSTM Model (with only one LSTM layer):loss: 0.78, accuracy: 71.44%\n",
    "deep LSTM Model (with only two LSTM layers) : loss: 0.53, accuracy: 83.12%\n",
    "sequential shallow GRU Model(only one GRU) : loss: 0.98, accuracy: 62.81%\n",
    "sequential shallow GRU Model(two GRU layers) : loss: 0.82, accuracy: 70.23%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Which model performs the best and why? (0.5 points) \n",
    "## How does it compare to baseline? (0.5 points)\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "The cross-sectional shallow model with only one hidden layer performs the best as it has a test accuracy score of 94.47% as the model has converged for a one hidden layer.\n",
    "\n",
    "The basel line accuracy scores are as follows below \n",
    "0         0.582035\n",
    "4         0.198995\n",
    "2         0.155402\n",
    "1         0.055905\n",
    "3         0.007663\n",
    "and our best model's accuracy is much higher at 94.47% than that of the baseline."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
