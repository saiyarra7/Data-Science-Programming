{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building a salary prediction system. The data set for this assignment includes information on job descriptions and salaries. Use this data set to see if you can predict the salary of a job posting (i.e., the `Salary` column in the data set) based on the job description. This is important, because this model can make a salary recommendation as soon as a job description is entered into a system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description of Variables\n",
    "\n",
    "The description of variables are provided in \"Jobs - Data Dictionary.docx\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goal\n",
    "\n",
    "Use the **jobs_alldata.csv** data set and build models to predict **salary**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "saldf = pd.read_csv('jobs_alldata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Salary</th>\n",
       "      <th>Job Description</th>\n",
       "      <th>Location</th>\n",
       "      <th>Min_years_exp</th>\n",
       "      <th>Technical</th>\n",
       "      <th>Comm</th>\n",
       "      <th>Travel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>67206</td>\n",
       "      <td>Civil Service Title: Regional Director Mental ...</td>\n",
       "      <td>Remote</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>88313</td>\n",
       "      <td>The New York City Comptrollerâ€™s Office Burea...</td>\n",
       "      <td>Remote</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>10-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>81315</td>\n",
       "      <td>With minimal supervision from the Deputy Commi...</td>\n",
       "      <td>East campus</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>76426</td>\n",
       "      <td>OPEN TO CURRENT BUSINESS PROMOTION COORDINATOR...</td>\n",
       "      <td>East campus</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>55675</td>\n",
       "      <td>Only candidates who are permanent in the Princ...</td>\n",
       "      <td>Southeast campus</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5-10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Salary                                    Job Description  \\\n",
       "0   67206  Civil Service Title: Regional Director Mental ...   \n",
       "1   88313  The New York City Comptrollerâ€™s Office Burea...   \n",
       "2   81315  With minimal supervision from the Deputy Commi...   \n",
       "3   76426  OPEN TO CURRENT BUSINESS PROMOTION COORDINATOR...   \n",
       "4   55675  Only candidates who are permanent in the Princ...   \n",
       "\n",
       "           Location  Min_years_exp  Technical  Comm Travel  \n",
       "0            Remote              5          2     3      0  \n",
       "1            Remote              5          2     4  10-15  \n",
       "2       East campus              5          3     3   5-10  \n",
       "3       East campus              1          1     3      0  \n",
       "4  Southeast campus              1          1     3   5-10  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saldf.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assign the \"target\" variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = saldf['Salary']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Mining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assign the \"text\" (input) variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Job Description    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for missing values\n",
    "\n",
    "saldf[['Job Description']].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = saldf['Job Description']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_set, test_set, train_y, test_y = train_test_split(input_data, target, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1689,), (1689,))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set.shape, train_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((724,), (724,))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set.shape, test_y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sklearn: Text preparation\n",
    "\n",
    "We need to prepare the text data. We'll use sklearn's CountVectorizer, which counts the frequency of words that appear in your entire data set.<br>\n",
    "CountVectorizer: https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TfidfVectorizer includes pre-processing, tokenization, filtering stop words\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_vect = TfidfVectorizer(stop_words='english')\n",
    "\n",
    "train_x_tr = tfidf_vect.fit_transform(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform the TfidfVectorizer transformation\n",
    "# Be careful: We are using the train fit to transform the test data set. Otherwise, the test data \n",
    "# features will be very different and match the train set!!!\n",
    "\n",
    "test_x_tr = tfidf_vect.transform(test_set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1689, 9914), (724, 9914))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x_tr.shape, test_x_tr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1689x9914 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 250443 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# These data sets are \"sparse matrix\". We can't see them unless we convert using toarray()\n",
    "train_x_tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.02913336, 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# These data sets are \"sparse matrix\". We can't see them unless we convert using toarray()\n",
    "train_x_tr.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Latent Semantic Analysis (Singular Value Decomposition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#If you are performing Latent Semantic Analysis, recommended number of components is 100\n",
    "\n",
    "svd = TruncatedSVD(n_components=300, n_iter=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x_lsa = svd.fit_transform(train_x_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1689, 300)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x_lsa.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.24720598, -0.20327125,  0.11489911, ..., -0.02279996,\n",
       "         0.00647618, -0.06844994],\n",
       "       [ 0.17294821, -0.13074886,  0.00477585, ...,  0.01940549,\n",
       "        -0.04161913, -0.010966  ],\n",
       "       [ 0.5877761 ,  0.365734  ,  0.13443229, ..., -0.01437579,\n",
       "         0.0099372 , -0.00641932],\n",
       "       ...,\n",
       "       [ 0.13385776, -0.10605211, -0.04018447, ..., -0.01465256,\n",
       "         0.02430085,  0.00872729],\n",
       "       [ 0.15340621, -0.12353644, -0.04283056, ..., -0.02456958,\n",
       "        -0.02298649, -0.04267142],\n",
       "       [ 0.21722752, -0.05642434,  0.31527024, ..., -0.00661978,\n",
       "        -0.02403752, -0.04506847]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x_lsa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's transform the test data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x_lsa = svd.transform(test_x_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(724, 300)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x_lsa.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing colums other than text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import FunctionTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Salary</th>\n",
       "      <th>Job Description</th>\n",
       "      <th>Location</th>\n",
       "      <th>Min_years_exp</th>\n",
       "      <th>Technical</th>\n",
       "      <th>Comm</th>\n",
       "      <th>Travel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>67206</td>\n",
       "      <td>Civil Service Title: Regional Director Mental ...</td>\n",
       "      <td>Remote</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>88313</td>\n",
       "      <td>The New York City Comptrollerâ€™s Office Burea...</td>\n",
       "      <td>Remote</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>10-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>81315</td>\n",
       "      <td>With minimal supervision from the Deputy Commi...</td>\n",
       "      <td>East campus</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>76426</td>\n",
       "      <td>OPEN TO CURRENT BUSINESS PROMOTION COORDINATOR...</td>\n",
       "      <td>East campus</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>55675</td>\n",
       "      <td>Only candidates who are permanent in the Princ...</td>\n",
       "      <td>Southeast campus</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5-10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Salary                                    Job Description  \\\n",
       "0   67206  Civil Service Title: Regional Director Mental ...   \n",
       "1   88313  The New York City Comptrollerâ€™s Office Burea...   \n",
       "2   81315  With minimal supervision from the Deputy Commi...   \n",
       "3   76426  OPEN TO CURRENT BUSINESS PROMOTION COORDINATOR...   \n",
       "4   55675  Only candidates who are permanent in the Princ...   \n",
       "\n",
       "           Location  Min_years_exp  Technical  Comm Travel  \n",
       "0            Remote              5          2     3      0  \n",
       "1            Remote              5          2     4  10-15  \n",
       "2       East campus              5          3     3   5-10  \n",
       "3       East campus              1          1     3      0  \n",
       "4  Southeast campus              1          1     3   5-10  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nontextdf = pd.read_csv('jobs_alldata.csv')\n",
    "nontextdf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split the data into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_set, test_set = train_test_split(saldf, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dropping the variables we can't use "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Salary</th>\n",
       "      <th>Location</th>\n",
       "      <th>Min_years_exp</th>\n",
       "      <th>Technical</th>\n",
       "      <th>Comm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>910</th>\n",
       "      <td>65141</td>\n",
       "      <td>HQ</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1291</th>\n",
       "      <td>51458</td>\n",
       "      <td>Southeast campus</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>62410</td>\n",
       "      <td>HQ</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2104</th>\n",
       "      <td>100548</td>\n",
       "      <td>HQ</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1869</th>\n",
       "      <td>86242</td>\n",
       "      <td>East campus</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Salary          Location  Min_years_exp  Technical  Comm\n",
       "910    65141                HQ              4          2     4\n",
       "1291   51458  Southeast campus              5          2     2\n",
       "491    62410                HQ              5          1     3\n",
       "2104  100548                HQ              2          5     2\n",
       "1869   86242       East campus              5          3     2"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = train_set.drop(['Job Description', 'Travel'], axis=1)\n",
    "test = test_set.drop(['Job Description', 'Travel'], axis=1)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separate the target variable (we don't want to transform it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_inputs = train.drop(['Salary'], axis=1)\n",
    "test_inputs = test.drop(['Salary'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Here i didnot transform a column because i could not see a pattern to transform a single column or combine 2 columns as it should not be done without a reason. But have done text mining and one hot encoding for categorical variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify the numerical columns\n",
    "numeric_columns = ['Min_years_exp','Technical','Comm']\n",
    "\n",
    "# Identify the categorical columns\n",
    "categorical_columns = ['Location']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_transformer = Pipeline(steps=[\n",
    "                ('imputer', SimpleImputer(strategy='median')),\n",
    "                ('scaler', StandardScaler())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='unknown')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = ColumnTransformer([\n",
    "        ('num', numeric_transformer, numeric_columns),\n",
    "        ('cat', categorical_transformer, categorical_columns)],\n",
    "        remainder='passthrough')\n",
    "\n",
    "#passtrough is an optional step. You don't have to use it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transform: fit_transform() for TRAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.57095113, -0.22153976,  0.98746763, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 1.12548619, -0.22153976, -1.28015008, ...,  0.        ,\n",
       "         1.        ,  0.        ],\n",
       "       [ 1.12548619, -1.04754561, -0.14634123, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       ...,\n",
       "       [ 1.12548619, -1.04754561,  0.98746763, ...,  1.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [-1.09265404,  0.6044661 , -1.28015008, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 1.12548619,  0.6044661 , -2.41395893, ...,  0.        ,\n",
       "         0.        ,  0.        ]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fit and transform the train data\n",
    "train_x = preprocessor.fit_transform(train_inputs)\n",
    "\n",
    "train_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1689, 8)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tranform: transform() for TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.57095113,  0.6044661 ,  0.98746763, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [-1.09265404, -1.04754561, -0.14634123, ...,  0.        ,\n",
       "         1.        ,  0.        ],\n",
       "       [ 0.57095113, -1.04754561, -0.14634123, ...,  1.        ,\n",
       "         0.        ,  0.        ],\n",
       "       ...,\n",
       "       [ 0.57095113, -1.04754561, -0.14634123, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [-1.09265404,  0.6044661 , -0.14634123, ...,  1.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 1.12548619,  0.6044661 , -1.28015008, ...,  0.        ,\n",
       "         0.        ,  0.        ]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transform the test data\n",
    "test_x = preprocessor.transform(test_inputs)\n",
    "\n",
    "test_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(724, 8)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining Text mining data and non-text columns processed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x_cb=np.concatenate((train_x_lsa,train_x),axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.24720598, -0.20327125,  0.11489911, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.17294821, -0.13074886,  0.00477585, ...,  0.        ,\n",
       "         1.        ,  0.        ],\n",
       "       [ 0.5877761 ,  0.365734  ,  0.13443229, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       ...,\n",
       "       [ 0.13385776, -0.10605211, -0.04018447, ...,  1.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.15340621, -0.12353644, -0.04283056, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.21722752, -0.05642434,  0.31527024, ...,  0.        ,\n",
       "         0.        ,  0.        ]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x_cb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1689, 308)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x_cb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x_cb=np.concatenate((test_x_lsa,test_x),axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.22442943, -0.15304556, -0.07083585, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.18129172, -0.14482415, -0.05639426, ...,  0.        ,\n",
       "         1.        ,  0.        ],\n",
       "       [ 0.25478046, -0.19879586, -0.07065608, ...,  1.        ,\n",
       "         0.        ,  0.        ],\n",
       "       ...,\n",
       "       [ 0.27755586, -0.18287792,  0.03599143, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.14498797, -0.11293755, -0.07782072, ...,  1.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.26692051, -0.08935042,  0.44355519, ...,  0.        ,\n",
       "         0.        ,  0.        ]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x_cb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(724, 308)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x_cb.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find the Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78566.0307874482"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#First find the average value of the target\n",
    "\n",
    "mean_value = np.mean(train_y)\n",
    "\n",
    "mean_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict all values as the mean\n",
    "\n",
    "baseline_pred = np.repeat(mean_value, len(test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline RMSE: 28294.892856870818\n"
     ]
    }
   ],
   "source": [
    "baseline_mse = mean_squared_error(test_y, baseline_pred)\n",
    "\n",
    "baseline_rmse = np.sqrt(baseline_mse)\n",
    "\n",
    "print('Baseline RMSE: {}' .format(baseline_rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore the SVDs - OPTIONAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6686490638820455"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svd.explained_variance_.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 6.88496587e-04,  8.57475540e-02,  9.35138953e-05, ...,\n",
       "         2.58331510e-04,  2.64894838e-04,  4.74548918e-04],\n",
       "       [-4.24457233e-04,  9.21278086e-02, -8.70152800e-05, ...,\n",
       "        -5.37307789e-04,  4.90695772e-04, -9.88739389e-04],\n",
       "       [-5.92600177e-04, -6.23455368e-02, -1.68140617e-04, ...,\n",
       "        -3.77315274e-04, -3.92896112e-04, -5.15104924e-04],\n",
       "       ...,\n",
       "       [ 1.54880303e-02,  8.39712028e-03,  1.51191855e-03, ...,\n",
       "         6.02299529e-03,  1.87934402e-03, -2.08995908e-03],\n",
       "       [-2.36825972e-02, -6.73228937e-03,  2.67184886e-05, ...,\n",
       "         3.42238707e-03, -3.90742033e-03, -3.59153477e-03],\n",
       "       [-1.66974419e-02, -9.74245930e-03,  4.03521347e-03, ...,\n",
       "        -3.84009561e-03,  5.06943722e-04,  9.95543406e-03]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#These are the all the components:\n",
    "svd.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300, 9914)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svd.components_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Let's select the first component:\n",
    "\n",
    "first_component = svd.components_[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the weights in the first component, and get the indeces\n",
    "\n",
    "indeces = np.argsort(first_component).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's get the feature names from the count vectorizer:\n",
    "feat_names = tfidf_vect.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bureau \t\tweight = 0.10717931879805626\n",
      "management \t\tweight = 0.10960765437645147\n",
      "new \t\tweight = 0.12230386159112756\n",
      "design \t\tweight = 0.12986195254896962\n",
      "city \t\tweight = 0.1360852112302988\n",
      "project \t\tweight = 0.13846106935768068\n",
      "dep \t\tweight = 0.14965285958788005\n",
      "construction \t\tweight = 0.15479839429867367\n",
      "wastewater \t\tweight = 0.15841529884565272\n",
      "water \t\tweight = 0.26425044968095424\n"
     ]
    }
   ],
   "source": [
    "#Print the last 10 terms (i.e., the 10 terms that have the highest weigths)\n",
    "\n",
    "for index in indeces[-10:]:\n",
    "    print(feat_names[index], \"\\t\\tweight =\", first_component[index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(max_depth=10, max_features=2)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "tree_reg = DecisionTreeRegressor(max_depth = 10, max_features = 2) \n",
    "\n",
    "tree_reg.fit(train_x_cb, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train RMSE: 18462.013568912105\n"
     ]
    }
   ],
   "source": [
    "#Train RMSE\n",
    "train_pred = tree_reg.predict(train_x_cb)\n",
    "\n",
    "train_mse = mean_squared_error(train_y, train_pred)\n",
    "\n",
    "train_rmse = np.sqrt(train_mse)\n",
    "\n",
    "print('Train RMSE: {}' .format(train_rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 25393.464381007892\n"
     ]
    }
   ],
   "source": [
    "#Test RMSE\n",
    "test_pred = tree_reg.predict(test_x_cb)\n",
    "\n",
    "test_mse = mean_squared_error(test_y, test_pred)\n",
    "\n",
    "test_rmse = np.sqrt(test_mse)\n",
    "\n",
    "print('Test RMSE: {}' .format(test_rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Voting regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingRegressor(estimators=[('dt', DecisionTreeRegressor(max_depth=20)),\n",
       "                            ('svr', SVR(C=10, epsilon=0.01)),\n",
       "                            ('sgd', SGDRegressor(max_iter=10000))],\n",
       "                weights=[0.6, 0.2, 0.2])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.linear_model import SGDRegressor \n",
    "from sklearn.svm import SVR \n",
    "from sklearn.ensemble import VotingRegressor\n",
    "\n",
    "\n",
    "dtree_reg = DecisionTreeRegressor(max_depth=20)\n",
    "svm_reg = SVR(kernel=\"rbf\", C=10, epsilon=0.01, gamma='scale') \n",
    "sgd_reg = SGDRegressor(max_iter=10000, tol=1e-3)\n",
    "\n",
    "voting_reg = VotingRegressor(\n",
    "            estimators=[('dt', dtree_reg), ('svr', svm_reg), ('sgd', sgd_reg)],\n",
    "                        weights=[0.6, 0.2, 0.2])\n",
    "\n",
    "voting_reg.fit(train_x_cb, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train RMSE: 8778.619007225168\n"
     ]
    }
   ],
   "source": [
    "#Train RMSE\n",
    "train_pred = voting_reg.predict(train_x_cb)\n",
    "\n",
    "train_mse = mean_squared_error(train_y, train_pred)\n",
    "\n",
    "train_rmse = np.sqrt(train_mse)\n",
    "\n",
    "print('Train RMSE: {}' .format(train_rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 18247.085889126734\n"
     ]
    }
   ],
   "source": [
    "#Test RMSE\n",
    "test_pred = voting_reg.predict(test_x_cb)\n",
    "\n",
    "test_mse = mean_squared_error(test_y, test_pred)\n",
    "\n",
    "test_rmse = np.sqrt(test_mse)\n",
    "\n",
    "print('Test RMSE: {}' .format(test_rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingRegressor(estimators=[('dt',\n",
       "                             DecisionTreeRegressor(max_depth=5,\n",
       "                                                   min_samples_leaf=10)),\n",
       "                            ('svr', SVR(C=10, epsilon=0.01)),\n",
       "                            ('sgd', SGDRegressor(max_iter=10000))],\n",
       "                weights=[0.6, 0.2, 0.2])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Let's restrict the depth in decision tree\n",
    "dtree_reg = DecisionTreeRegressor(min_samples_leaf = 10, max_depth=5)\n",
    "svm_reg = SVR(kernel=\"rbf\", C=10, epsilon=0.01, gamma='scale') \n",
    "sgd_reg = SGDRegressor(max_iter=10000, tol=1e-3)\n",
    "\n",
    "voting_reg = VotingRegressor(\n",
    "            estimators=[('dt', dtree_reg), ('svr', svm_reg), ('sgd', sgd_reg)],\n",
    "                        weights=[0.6, 0.2, 0.2])\n",
    "\n",
    "\n",
    "voting_reg.fit(train_x_cb, train_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train RMSE: 21575.92658609869\n"
     ]
    }
   ],
   "source": [
    "#Train RMSE\n",
    "train_pred = voting_reg.predict(train_x_cb)\n",
    "\n",
    "train_mse = mean_squared_error(train_y, train_pred)\n",
    "\n",
    "train_rmse = np.sqrt(train_mse)\n",
    "\n",
    "print('Train RMSE: {}' .format(train_rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 23269.315377788254\n"
     ]
    }
   ],
   "source": [
    "#Test RMSE\n",
    "test_pred = voting_reg.predict(test_x_cb)\n",
    "\n",
    "test_mse = mean_squared_error(test_y, test_pred)\n",
    "\n",
    "test_rmse = np.sqrt(test_mse)\n",
    "\n",
    "print('Test RMSE: {}' .format(test_rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeRegressor Test rmse= 25219.498646091455\n",
      "SVR Test rmse= 28420.40182338191\n",
      "SGDRegressor Test rmse= 20576.993242733573\n",
      "VotingRegressor Test rmse= 23237.211104937775\n"
     ]
    }
   ],
   "source": [
    "for reg in (dtree_reg, svm_reg, sgd_reg, voting_reg):\n",
    "    reg.fit(train_x_cb, train_y)\n",
    "    test_y_pred = reg.predict(test_x_cb)\n",
    "    print(reg.__class__.__name__, 'Test rmse=', np.sqrt(mean_squared_error(test_y, test_y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Voting regressor model with weights "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingRegressor(estimators=[('dt', DecisionTreeRegressor(max_depth=20)),\n",
       "                            ('svr', SVR(C=10, epsilon=0.01)),\n",
       "                            ('sgd', SGDRegressor(max_iter=10000))],\n",
       "                weights=[0.33, 0.33, 0.34])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.linear_model import SGDRegressor \n",
    "from sklearn.svm import SVR \n",
    "from sklearn.ensemble import VotingRegressor\n",
    "\n",
    "\n",
    "dtree_reg = DecisionTreeRegressor(max_depth=20)\n",
    "svm_reg = SVR(kernel=\"rbf\", C=10, epsilon=0.01, gamma='scale') \n",
    "sgd_reg = SGDRegressor(max_iter=10000, tol=1e-3)\n",
    "\n",
    "voting_reg = VotingRegressor(\n",
    "            estimators=[('dt', dtree_reg), ('svr', svm_reg), ('sgd', sgd_reg)],\n",
    "                        weights=[0.33, 0.33, 0.34])\n",
    "\n",
    "voting_reg.fit(train_x_cb, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train RMSE: 14684.737208900684\n"
     ]
    }
   ],
   "source": [
    "#Train RMSE\n",
    "train_pred = voting_reg.predict(train_x_cb)\n",
    "\n",
    "train_mse = mean_squared_error(train_y, train_pred)\n",
    "\n",
    "train_rmse = np.sqrt(train_mse)\n",
    "\n",
    "print('Train RMSE: {}' .format(train_rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 19280.543397683497\n"
     ]
    }
   ],
   "source": [
    "#Test RMSE\n",
    "test_pred = voting_reg.predict(test_x_cb)\n",
    "\n",
    "test_mse = mean_squared_error(test_y, test_pred)\n",
    "\n",
    "test_rmse = np.sqrt(test_mse)\n",
    "\n",
    "print('Test RMSE: {}' .format(test_rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Voting Regressor model with Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaggingRegressor(base_estimator=SGDRegressor(), max_samples=1000,\n",
       "                 n_estimators=50, n_jobs=-1)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingRegressor\n",
    "\n",
    "\n",
    "#If you want to do pasting, change \"bootstrap=False\"\n",
    "#n_jobs=-1 means use all CPU cores\n",
    "#bagging automatically performs soft voting\n",
    "\n",
    "bag_reg = BaggingRegressor( \n",
    "            SGDRegressor(), n_estimators=50, \n",
    "            max_samples=1000, bootstrap=True, n_jobs=-1) \n",
    "\n",
    "bag_reg.fit(train_x_cb, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train RMSE: 20650.125753723147\n"
     ]
    }
   ],
   "source": [
    "#Train RMSE\n",
    "train_pred = bag_reg.predict(train_x_cb)\n",
    "\n",
    "train_mse = mean_squared_error(train_y, train_pred)\n",
    "\n",
    "train_rmse = np.sqrt(train_mse)\n",
    "\n",
    "print('Train RMSE: {}' .format(train_rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 22031.26868836874\n"
     ]
    }
   ],
   "source": [
    "#Test RMSE\n",
    "test_pred = bag_reg.predict(test_x_cb)\n",
    "\n",
    "test_mse = mean_squared_error(test_y, test_pred)\n",
    "\n",
    "test_rmse = np.sqrt(test_mse)\n",
    "\n",
    "print('Test RMSE: {}' .format(test_rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Boosting model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#AdaBoosting Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostRegressor(base_estimator=DecisionTreeRegressor(max_depth=10),\n",
       "                  learning_rate=0.1, n_estimators=500)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostRegressor \n",
    "\n",
    "#Create Adapative Boosting with Decision Stumps (depth=10)\n",
    "ada_reg = AdaBoostRegressor( \n",
    "            DecisionTreeRegressor(max_depth=10), n_estimators=500, \n",
    "            learning_rate=0.1) \n",
    "\n",
    "ada_reg.fit(train_x_cb, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train RMSE: 2900.8903801670617\n"
     ]
    }
   ],
   "source": [
    "#Train RMSE\n",
    "train_pred = ada_reg.predict(train_x_cb)\n",
    "\n",
    "train_mse = mean_squared_error(train_y, train_pred)\n",
    "\n",
    "train_rmse = np.sqrt(train_mse)\n",
    "\n",
    "print('Train RMSE: {}' .format(train_rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 15465.78556942667\n"
     ]
    }
   ],
   "source": [
    "#Test RMSE\n",
    "test_pred = ada_reg.predict(test_x_cb)\n",
    "\n",
    "test_mse = mean_squared_error(test_y, test_pred)\n",
    "\n",
    "test_rmse = np.sqrt(test_mse)\n",
    "\n",
    "print('Test RMSE: {}' .format(test_rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Early Stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Notice that learning rate and tol are high to see early stopping\n",
    "ada_reg = AdaBoostRegressor( \n",
    "            DecisionTreeRegressor(max_depth=5), n_estimators=300, \n",
    "           learning_rate=1) \n",
    "\n",
    "ada_reg.fit(train_x_cb, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train RMSE\n",
    "train_pred = ada_reg.predict(train_x_cb)\n",
    "\n",
    "train_mse = mean_squared_error(train_y, train_pred)\n",
    "\n",
    "train_rmse = np.sqrt(train_mse)\n",
    "\n",
    "print('Train RMSE: {}' .format(train_rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test RMSE\n",
    "test_pred = ada_reg.predict(test_x_cb)\n",
    "\n",
    "test_mse = mean_squared_error(test_y, test_pred)\n",
    "\n",
    "test_rmse = np.sqrt(test_mse)\n",
    "\n",
    "print('Test RMSE: {}' .format(test_rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "#Default settings create 1 hidden layer with 100 neurons\n",
    "mlp_reg = MLPRegressor(hidden_layer_sizes=(100,), max_iter = 5000)\n",
    "mlp_reg.fit(train_x_cb, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train RMSE\n",
    "train_pred = mlp_reg.predict(train_x_cb)\n",
    "\n",
    "train_mse = mean_squared_error(train_y, train_pred)\n",
    "\n",
    "train_rmse = np.sqrt(train_mse)\n",
    "\n",
    "print('Train RMSE: {}' .format(train_rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_pred = mlp_reg.predict(test_x_cb)\n",
    "\n",
    "mlp_mse = mean_squared_error(test_y, mlp_pred)\n",
    "\n",
    "mlp_rmse = np.sqrt(mlp_mse)\n",
    "\n",
    "print('MLP RMSE: {}' .format(mlp_rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dnn_reg = MLPRegressor(hidden_layer_sizes=(100, 100, 100), max_iter = 10000, tol = 0.0001, early_stopping = True)\n",
    "dnn_reg.fit(train_x_cb, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pred = dnn_reg.predict(train_x_cb)\n",
    "\n",
    "train_mse = mean_squared_error(train_y, train_pred)\n",
    "\n",
    "train_rmse = np.sqrt(train_mse)\n",
    "\n",
    "print('Train RMSE: {}' .format(train_rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dnn_pred = dnn_reg.predict(test_x_cb)\n",
    "\n",
    "dnn_mse = mean_squared_error(test_y, dnn_pred)\n",
    "\n",
    "dnn_rmse = np.sqrt(dnn_mse)\n",
    "\n",
    "print('DNN RMSE: {}' .format(dnn_rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Default settings create 1 hidden layer with 100 neurons\n",
    "mlp_reg = MLPRegressor(hidden_layer_sizes=(100,), max_iter=1000)\n",
    "\n",
    "mlp_reg.fit(train_x_cb, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train RMSE\n",
    "train_pred = mlp_reg.predict(train_x_cb)\n",
    "\n",
    "train_mse = mean_squared_error(train_y, train_pred)\n",
    "\n",
    "train_rmse = np.sqrt(train_mse)\n",
    "\n",
    "print('Train RMSE: {}' .format(train_rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test RMSE\n",
    "test_pred = mlp_reg.predict(test_x_cb)\n",
    "\n",
    "test_mse = mean_squared_error(test_y, test_pred)\n",
    "\n",
    "test_rmse = np.sqrt(test_mse)\n",
    "\n",
    "print('Test RMSE: {}' .format(test_rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dnn_reg = MLPRegressor(hidden_layer_sizes=(50,50,50,50,50),\n",
    "                       max_iter=1000)\n",
    "\n",
    "dnn_reg.fit(train_x_cb, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train RMSE\n",
    "train_pred = dnn_reg.predict(train_x_cb)\n",
    "\n",
    "train_mse = mean_squared_error(train_y, train_pred)\n",
    "\n",
    "train_rmse = np.sqrt(train_mse)\n",
    "\n",
    "print('Train RMSE: {}' .format(train_rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test RMSE\n",
    "test_pred = dnn_reg.predict(test_x_cb)\n",
    "\n",
    "test_mse = mean_squared_error(test_y, test_pred)\n",
    "\n",
    "test_rmse = np.sqrt(test_mse)\n",
    "\n",
    "print('Test RMSE: {}' .format(test_rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dnn_reg = MLPRegressor(hidden_layer_sizes=(50,50,50),\n",
    "                       max_iter=1000,\n",
    "                       early_stopping=True,\n",
    "                      alpha = 0.1)\n",
    "\n",
    "dnn_reg.fit(train_x_cb, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train RMSE\n",
    "train_pred = dnn_reg.predict(train_x_cb)\n",
    "\n",
    "train_mse = mean_squared_error(train_y, train_pred)\n",
    "\n",
    "train_rmse = np.sqrt(train_mse)\n",
    "\n",
    "print('Train RMSE: {}' .format(train_rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test RMSE\n",
    "test_pred = dnn_reg.predict(test_x_cb)\n",
    "\n",
    "test_mse = mean_squared_error(test_y, test_pred)\n",
    "\n",
    "test_rmse = np.sqrt(test_mse)\n",
    "\n",
    "print('Test RMSE: {}' .format(test_rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid search\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "param_grid = [\n",
    "    {'min_samples_leaf': np.arange(10, 30), \n",
    "     'max_depth': np.arange(10,30)}\n",
    "  ]\n",
    "\n",
    "tree_reg = DecisionTreeRegressor()\n",
    "\n",
    "grid_search = RandomizedSearchCV(tree_reg, param_grid, cv=5, n_iter=10,\n",
    "                           scoring='neg_mean_squared_error', verbose=1,\n",
    "                           return_train_score=True)\n",
    "\n",
    "grid_search.fit(train_x_cb, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvres = grid_search.cv_results_\n",
    "\n",
    "for mean_score, params in zip(cvres[\"mean_test_score\"], cvres[\"params\"]):\n",
    "    print(np.sqrt(-mean_score), params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train RMSE\n",
    "train_pred = grid_search.best_estimator_.predict(train_x_cb)\n",
    "\n",
    "train_mse = mean_squared_error(train_y, train_pred)\n",
    "\n",
    "train_rmse = np.sqrt(train_mse)\n",
    "\n",
    "print('Train RMSE: {}' .format(train_rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test RMSE\n",
    "test_pred = grid_search.best_estimator_.predict(test_x_cb)\n",
    "\n",
    "test_mse = mean_squared_error(test_y, test_pred)\n",
    "\n",
    "test_rmse = np.sqrt(test_mse)\n",
    "\n",
    "print('Test RMSE: {}' .format(test_rmse))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
